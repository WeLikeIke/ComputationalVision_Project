{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ranjbarpour_Tibaldi_Sajid_Computational_Vision.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9dJ8we9uZl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arezou Ranjbarpour Maralani\n",
        "# Lorenzo Tibaldi\n",
        "# Momina Sajid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlXlB8CUurrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4d4dd80-deb3-42fa-c9cb-5142a8914f6c"
      },
      "source": [
        "#Data manipulation\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "#Model creation\n",
        "import keras\n",
        "from keras import applications\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
        "\n",
        "#Files management\n",
        "import os\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6OzP6dpruf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plots accuracy and loss for train and validation sets of a trained model\n",
        "def plot_history(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN8ty9m3382j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data upload\n",
        "#When the file selection pops up, you should select a zip file containing the data\n",
        "files.upload()\n",
        "for i in os.listdir():\n",
        "    if i[0:2] == \"CV\":\n",
        "        !unzip \"$i\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZCDn5aaAo2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creation of training, validation and test sets\n",
        "train_X = []\n",
        "train_Y = []\n",
        "\n",
        "test_X = []\n",
        "test_Y = []\n",
        "\n",
        "data = [\"seg_train\",\"seg_test\"]\n",
        "Ts = [train_X,test_X,train_Y,test_Y]\n",
        "for i,d in enumerate(data):\n",
        "    lbl = -1\n",
        "    for j in os.listdir(d):\n",
        "        #print(j)\n",
        "        lbl += 1\n",
        "        for n in os.listdir(os.path.join(d,j)):\n",
        "            \n",
        "            img = np.asarray(Image.open(os.path.join(d,j,n)).resize((200,200),Image.ANTIALIAS))\n",
        "            Ts[i].append(img)\n",
        "            #print(np.shape(Ts[i]),n)\n",
        "            Ts[i+2].append(lbl)\n",
        "        \n",
        "num_classes = lbl + 1\n",
        "\n",
        "Train_X = np.array(train_X)\n",
        "train_Y = np.array(train_Y)\n",
        "Test_X = np.array(test_X)\n",
        "test_Y = np.array(test_Y)\n",
        "\n",
        "Train_X, Val_X, train_Y, val_Y = train_test_split(Train_X, train_Y, test_size=0.3, random_state=7)\n",
        "\n",
        "input_size = np.shape(Test_X)[1:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSvAJ9CHbVp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot of an image in the training set\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.title(train_Y[77])\n",
        "plt.imshow(Train_X[77])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpLMR3741-TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading Xception and prepares the model with and without fine tuning\n",
        "train_X = applications.xception.preprocess_input(Train_X)\n",
        "val_X = applications.xception.preprocess_input(Val_X)\n",
        "test_X = applications.xception.preprocess_input(Test_X)\n",
        "\n",
        "premodel = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
        "\n",
        "\n",
        "for layer in premodel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(premodel.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation=\"relu\")(x)\n",
        "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])\n",
        "finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y), verbose = 0)\n",
        "\n",
        "for layer in finemodel.layers[-9:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW0Fhddqu6SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading ResNet50V2 and prepares the model with and without fine tuning\n",
        "train_X = applications.resnet_v2.preprocess_input(Train_X)\n",
        "val_X = applications.resnet_v2.preprocess_input(Val_X)\n",
        "test_X = applications.resnet_v2.preprocess_input(Test_X)\n",
        "\n",
        "premodel = applications.ResNet50V2(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
        "\n",
        "\n",
        "for layer in premodel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(premodel.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation=\"relu\")(x)\n",
        "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])\n",
        "finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y), verbose = 0)\n",
        "\n",
        "for layer in finemodel.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w45y4APayhhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading InceptionV3 and prepares the model with and without fine tuning\n",
        "train_X = applications.inception_v3.preprocess_input(Train_X)\n",
        "val_X = applications.inception_v3.preprocess_input(Val_X)\n",
        "test_X = applications.inception_v3.preprocess_input(Test_X)\n",
        "\n",
        "premodel = applications.InceptionV3(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
        "\n",
        "\n",
        "for layer in premodel.layers:\n",
        "    if layer.name[:5] != \"batch\":\n",
        "        layer.trainable = False\n",
        "\n",
        "x = Flatten()(premodel.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation=\"relu\")(x)\n",
        "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
        "\n",
        "\n",
        "for layer in finemodel.layers[-18:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpkX9wdjyTpv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4b9c6ea9-87e7-4e53-dcab-14709b469d87"
      },
      "source": [
        "#Loading MobileNetV2 and prepares the model with and without fine tuning\n",
        "train_X = applications.mobilenet_v2.preprocess_input(Train_X)\n",
        "val_X = applications.mobilenet_v2.preprocess_input(Val_X)\n",
        "test_X = applications.mobilenet_v2.preprocess_input(Test_X)\n",
        "\n",
        "premodel = applications.MobileNetV2(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
        "\n",
        "\n",
        "for layer in premodel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(premodel.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation=\"relu\")(x)\n",
        "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
        "\n",
        "\n",
        "for layer in finemodel.layers[-9:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyjtwzm-yUgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading DenseNet201 and prepares the model with and without fine tuning\n",
        "train_X = applications.densenet.preprocess_input(Train_X)\n",
        "val_X = applications.densenet.preprocess_input(Val_X)\n",
        "test_X = applications.densenet.preprocess_input(Test_X)\n",
        "\n",
        "premodel = applications.DenseNet201(weights = \"imagenet\", include_top=False, input_shape = input_size)\n",
        "\n",
        "\n",
        "for layer in premodel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(premodel.output)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation=\"relu\")(x)\n",
        "finemodel = Model(inputs = premodel.inputs, outputs = x)\n",
        "\n",
        "\n",
        "for layer in finemodel.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "finemodel.compile(keras.optimizers.Adam(learning_rate = 0.0001), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92-zIO9pR8XT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "851c4df1-1f51-45a0-e8a6-c630e4abb805"
      },
      "source": [
        "%%time\n",
        "#Predicting the features using the selected model\n",
        "F_train = premodel.predict(train_X,batch_size=256, verbose=1)\n",
        "F_val =  premodel.predict(val_X,batch_size=111, verbose=1)\n",
        "F_test = premodel.predict(test_X,batch_size=100, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1540/1540 [==============================] - 16s 10ms/step\n",
            "660/660 [==============================] - 10s 15ms/step\n",
            "600/600 [==============================] - 6s 11ms/step\n",
            "CPU times: user 19.6 s, sys: 12.8 s, total: 32.4 s\n",
            "Wall time: 32.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TudobCikxXZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Definition of the top model, the classifier\n",
        "mainmodel = Sequential()\n",
        "mainmodel.add(Flatten(input_shape = np.shape(premodel.output)[1:]))\n",
        "mainmodel.add(BatchNormalization())\n",
        "mainmodel.add(Dense(512, activation=\"relu\"))\n",
        "mainmodel.add(Dropout(0.5))\n",
        "mainmodel.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "mainmodel.compile(keras.optimizers.Adam(), keras.losses.sparse_categorical_crossentropy, [\"accuracy\"])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db32yx7vd0Os",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "41aa6d29-abf0-4314-cfdb-bb63086901e4"
      },
      "source": [
        "#Train on the Intermediate features predicted before\n",
        "history = mainmodel.fit(F_train, train_Y, batch_size=154, epochs = 16, validation_data=(F_val, val_Y))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1540 samples, validate on 660 samples\n",
            "Epoch 1/16\n",
            "1540/1540 [==============================] - 1s 542us/step - loss: 0.3372 - accuracy: 0.9058 - val_loss: 0.1329 - val_accuracy: 0.9879\n",
            "Epoch 2/16\n",
            "1540/1540 [==============================] - 1s 409us/step - loss: 0.1470 - accuracy: 0.9948 - val_loss: 0.1390 - val_accuracy: 0.9909\n",
            "Epoch 3/16\n",
            "1540/1540 [==============================] - 1s 414us/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.1533 - val_accuracy: 0.9939\n",
            "Epoch 4/16\n",
            "1540/1540 [==============================] - 1s 408us/step - loss: 0.0257 - accuracy: 0.9974 - val_loss: 0.1012 - val_accuracy: 0.9970\n",
            "Epoch 5/16\n",
            "1540/1540 [==============================] - 1s 410us/step - loss: 0.0147 - accuracy: 0.9987 - val_loss: 0.3538 - val_accuracy: 0.9939\n",
            "Epoch 6/16\n",
            "1540/1540 [==============================] - 1s 407us/step - loss: 0.0542 - accuracy: 0.9981 - val_loss: 0.5405 - val_accuracy: 0.9939\n",
            "Epoch 7/16\n",
            "1540/1540 [==============================] - 1s 409us/step - loss: 5.3642e-08 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 0.9939\n",
            "Epoch 8/16\n",
            "1540/1540 [==============================] - 1s 405us/step - loss: 0.0275 - accuracy: 0.9987 - val_loss: 0.5919 - val_accuracy: 0.9939\n",
            "Epoch 9/16\n",
            "1540/1540 [==============================] - 1s 409us/step - loss: 0.0378 - accuracy: 0.9994 - val_loss: 0.6757 - val_accuracy: 0.9939\n",
            "Epoch 10/16\n",
            "1540/1540 [==============================] - 1s 410us/step - loss: 8.7311e-08 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.9939\n",
            "Epoch 11/16\n",
            "1540/1540 [==============================] - 1s 413us/step - loss: 5.3577e-05 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.9939\n",
            "Epoch 12/16\n",
            "1540/1540 [==============================] - 1s 418us/step - loss: 3.5608e-09 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.9939\n",
            "Epoch 13/16\n",
            "1540/1540 [==============================] - 1s 416us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6877 - val_accuracy: 0.9939\n",
            "Epoch 14/16\n",
            "1540/1540 [==============================] - 1s 414us/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.6062 - val_accuracy: 0.9924\n",
            "Epoch 15/16\n",
            "1540/1540 [==============================] - 1s 410us/step - loss: 5.8056e-09 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.9924\n",
            "Epoch 16/16\n",
            "1540/1540 [==============================] - 1s 411us/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.6176 - val_accuracy: 0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpOUzPBmr49K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot of the training, accuracy and loss\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5BoeLWUPtyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluation on the test set\n",
        "mainmodel.evaluate(F_test, test_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klt9Qs9qu11K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training taking the images as input and classifing them with the fine tuned model\n",
        "finehistory = finemodel.fit(train_X, train_Y, batch_size=154, epochs = 16, validation_data=(val_X, val_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2GVjOE2vURo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the history of the fine tuned model\n",
        "plot_history(finehistory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyJh4PsmvWvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluation on the test set\n",
        "finemodel.evaluate(test_X, test_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZKRO3FMWp2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "afa803ea-e10e-442d-df46-2c4a3cece286"
      },
      "source": [
        "#Preprocessing for the dimensionality reduction algorithms\n",
        "Fr_train = F_train.reshape(np.shape(F_train)[0],-1)\n",
        "Fr_val = F_val.reshape(np.shape(F_val)[0],-1)\n",
        "Fr_test = F_test.reshape(np.shape(F_test)[0],-1)\n",
        "print(Fr_train.shape,Fr_val.shape,Fr_test.shape)\n",
        "\n",
        "features = np.array([*Fr_train, *Fr_val, *Fr_test])\n",
        "labels = np.array([*train_Y, *val_Y, *test_Y])\n",
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1540, 100352) (660, 100352) (600, 100352)\n",
            "(2800, 100352) (2800,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxXvhbvzBVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#How many dimensions? we selected 3 for a 3D view\n",
        "dimensionality = 3"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCCRfEY1CBJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "53e20ef3-4029-404e-9efb-5b7deb05f00b"
      },
      "source": [
        "%%time\n",
        "#Reduction by PCA\n",
        "F3D = PCA(dimensionality).fit_transform(features)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18.7 s, sys: 786 ms, total: 19.5 s\n",
            "Wall time: 10.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TILO6707mOJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "efcdaff7-4a45-495b-b44d-ba783687bc4e"
      },
      "source": [
        "%%time\n",
        "#Reduction by T-SNE\n",
        "f3d = TSNE(dimensionality).fit_transform(features)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26min 16s, sys: 3.25 s, total: 26min 20s\n",
            "Wall time: 25min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9lN_TRQ8boR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the npy for the post visualization\n",
        "np.save(\"PCA.npy\", F3D)\n",
        "np.save(\"TSNE.npy\", f3d)\n",
        "np.save(\"labels.npy\", labels)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXVAmVGUtTvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9f75e470-0489-46fb-c286-ef2c410e655e"
      },
      "source": [
        "#Silhouette score calculation \n",
        "print(\"PCA silhouette score:\",silhouette_score(F3D,labels))\n",
        "print(\"TSNE silhouette score:\",silhouette_score(f3d,labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA silhouette score: 0.6580159\n",
            "TSNE silhouette score: 0.4279452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiuiIRivbhaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}